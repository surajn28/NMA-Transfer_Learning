{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:13:54.647816Z","iopub.status.busy":"2022-07-26T08:13:54.646985Z","iopub.status.idle":"2022-07-26T08:14:07.194933Z","shell.execute_reply":"2022-07-26T08:14:07.193819Z","shell.execute_reply.started":"2022-07-26T08:13:54.647771Z"},"id":"L49WF_xGw4vI","outputId":"0fa3ae8c-9ec9-4fd8-e089-65e94aa89b25","trusted":true},"outputs":[],"source":["# get the pytorch implementation of facenet - https://github.com/timesler/facenet-pytorch\n","!pip install facenet-pytorch --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:12:46.156263Z","iopub.status.busy":"2022-07-26T08:12:46.155594Z","iopub.status.idle":"2022-07-26T08:13:54.644629Z","shell.execute_reply":"2022-07-26T08:13:54.643484Z","shell.execute_reply.started":"2022-07-26T08:12:46.156226Z"},"trusted":true},"outputs":[],"source":["# gdown is used to download the datasets from google drive, this is more general than the google.drive package and also works in kaggle\n","! conda install -y gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:14:07.197353Z","iopub.status.busy":"2022-07-26T08:14:07.196565Z","iopub.status.idle":"2022-07-26T08:14:07.378711Z","shell.execute_reply":"2022-07-26T08:14:07.377717Z","shell.execute_reply.started":"2022-07-26T08:14:07.197322Z"},"id":"taKuFbCeceL0","trusted":true},"outputs":[],"source":["# imports\n","import os\n","import gc\n","import csv\n","import glob\n","import pandas as pd\n","import PIL\n","import h5py\n","import multiprocessing\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.data import Dataset\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n","import os.path as osp\n","\n","from facenet_pytorch import MTCNN, InceptionResnetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:14:07.381234Z","iopub.status.busy":"2022-07-26T08:14:07.380904Z","iopub.status.idle":"2022-07-26T08:14:32.923996Z","shell.execute_reply":"2022-07-26T08:14:32.922821Z","shell.execute_reply.started":"2022-07-26T08:14:07.381199Z"},"id":"NXjU1MfGSt4c","outputId":"fcaf1b2a-544c-4fe1-b38a-01b40c501e68","trusted":true},"outputs":[],"source":["# downloading data sets\n","!gdown --id 1lrT0Ub2QoJ3f3rHpRmFYRwuTUfh7bTUI # train set\n","!gdown --id 1dYF26xgFpoUtnBDmhYWMcvyX_qEeAPDp # validation set\n","!gdown --id 1YusblOsvP77d10Vw3TUUGcSbRwSVK3Ep # holdout set\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:14:47.903322Z","iopub.status.busy":"2022-07-26T08:14:47.902965Z","iopub.status.idle":"2022-07-26T08:14:47.914365Z","shell.execute_reply":"2022-07-26T08:14:47.912994Z","shell.execute_reply.started":"2022-07-26T08:14:47.903294Z"},"id":"rsgC7zmRleKV","trusted":true},"outputs":[],"source":["# Data loader with data augmentation\n","\n","class H5FileDataset(Dataset):\n","    # dataloader output: (pic_indices, color_channel, height, width)\n","    def __init__(self, h5_filename, transform=None, target_transform=None):\n","        self.h5_filename = h5_filename\n","        self.img_h5_file = self._load_h5_file(self.h5_filename)\n","        self.all_labels = self.img_h5_file['labels'][:]\n","        self.transform = transform  \n","\n","    def __len__(self):\n","        return len(self.all_labels)\n","\n","    def __getitem__(self, idx):\n","        img = self.img_h5_file['img_data'][idx]\n","        label = self.img_h5_file['labels'][idx]\n","\n","        label = torch.as_tensor(label, dtype=torch.float64)\n","\n","        img = np.transpose(img, [2, 0, 1])\n","        img = img.astype(np.double)\n","        img = torch.as_tensor(img, dtype=torch.float64)\n","        # img = img/255\n","        if self.transform is not None:\n","            img = self.transform(img)  \n","        return img, label\n","\n","    def _load_h5_file(self, h5_filename):\n","        file = h5py.File(h5_filename, 'r')\n","        img_data = file['pic_mat']\n","        img_labels = file['labels']\n","        return dict(file=file, img_data=img_data, labels=img_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load data and apply transforms\n","composed = transforms.Compose([transforms.RandomCrop([500, 500]), transforms.Resize([160, 160])])\n","\n","trainset = H5FileDataset('kdef_train_dataset.h5', transform=composed)\n","testset = H5FileDataset('kdef_val_dataset.h5', transform=composed)\n","holdoutset = H5FileDataset('kdef_test_dataset.h5', transform=composed)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n","holdoutloader = torch.utils.data.DataLoader(holdoutset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# hyper-parameters\n","use_cuda = torch.cuda.is_available()\n","best_acc = 0\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","batch_size = 100\n","max_epochs = 25\n","\n","base_learning_rate = 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:53:07.446150Z","iopub.status.busy":"2022-07-26T08:53:07.445794Z","iopub.status.idle":"2022-07-26T08:53:07.467178Z","shell.execute_reply":"2022-07-26T08:53:07.466143Z","shell.execute_reply.started":"2022-07-26T08:53:07.446120Z"},"id":"ZFpQN-iaodIU","trusted":true},"outputs":[],"source":["# define train and test loop\n","def train(net, epoch, trainloader, use_cuda=True):\n","  net.train()\n","  train_loss = 0\n","  correct = 0\n","  total = 0\n","  for batch_idx, (inputs, targets) in enumerate(trainloader):\n","    targets = np.array(targets, dtype=int)\n","    targets = torch.as_tensor(targets, dtype=torch.long)\n","    if use_cuda:\n","      inputs, targets = inputs.cuda(), targets.cuda()\n","\n","    optimizer.zero_grad()\n","    inputs, targets = Variable(inputs), Variable(targets)\n","    outputs = net(inputs)\n","    loss = criterion(outputs, targets)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    train_loss += loss.item()\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += targets.size(0)\n","    correct += predicted.eq(targets.data).cpu().sum()\n","\n","  return (train_loss/batch_idx, 100.*correct/total)\n","\n","\n","def test(net, epoch, testloader, outModelName, use_cuda=True):\n","  global best_acc\n","  net.eval()\n","  test_loss, correct, total = 0, 0, 0\n","  with torch.no_grad():\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","      targets = np.array(targets, dtype=int)\n","      targets = torch.as_tensor(targets, dtype=torch.long)\n","      if use_cuda:\n","        inputs, targets = inputs.cuda(), targets.cuda()\n","\n","      outputs = net(inputs)\n","      loss = criterion(outputs, targets)\n","\n","      test_loss += loss.item()\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += targets.size(0)\n","      correct += predicted.eq(targets.data).cpu().sum()\n","\n","      if batch_idx % 200 == 0:\n","        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        best_acc = acc\n","        checkpoint(net, acc, epoch, outModelName)\n","    return (test_loss/batch_idx, 100.*correct/total)\n","\n","\n","# checkpoint & adjust_learning_rate\n","def checkpoint(model, acc, epoch, outModelName):\n","  # Save checkpoint.\n","  print('Saving..')\n","  state = {\n","      'state_dict': model.state_dict(),\n","      'acc': acc,\n","      'epoch': epoch,\n","      'rng_state': torch.get_rng_state()\n","  }\n","  if not os.path.isdir('checkpoint'):\n","      os.mkdir('checkpoint')\n","  torch.save(state, f'./checkpoint/{outModelName}.t7')\n","\n","def adjust_learning_rate(optimizer, epoch):\n","  \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n","  lr = base_learning_rate\n","  if epoch <= 9 and lr > 0.1:\n","    # warm-up training for large minibatch\n","    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n","  if epoch >= 100:\n","    lr /= 10\n","  if epoch >= 150:\n","    lr /= 10\n","  for param_group in optimizer.param_groups:\n","    param_group['lr'] = lr"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-25T08:19:12.646867Z","iopub.status.busy":"2022-07-25T08:19:12.646222Z","iopub.status.idle":"2022-07-25T08:19:12.653859Z","shell.execute_reply":"2022-07-25T08:19:12.652841Z","shell.execute_reply.started":"2022-07-25T08:19:12.646832Z"},"id":"tzwmqwImlzkH","trusted":true},"outputs":[],"source":["## Uncomment and run to inspect/change structure of Facenet\n","\n","# net = InceptionResnetV1(pretrained='vggface2', classify=True)\n","# print(net) # shows structure of network\n","\n","# in_ftrs = net.logits.in_features # number of input features of the last layer of the classifier\n","# print(\"+ Previous Nr of Outputs: \" + str(net.logits.out_features)) # number of output features of the last layer of the classifier == num_classes\n","# net.logits = nn.Linear(in_ftrs, 2, )\n","# print(\"++++++ New Nr of Outputs: \" + str(net.logits.out_features))\n","\n","# in_ftrs = net.last_linear.in_features # number of input features of the last layer of the classifier\n","# print(\"+ Previous Nr of Outputs: \" + str(net.last_linear.out_features)) # number of output features of the last layer of the classifier == num_classes\n","# net.last_linear = nn.Linear(in_ftrs, 2, )\n","# print(\"++++++ New Nr of Outputs: \" + str(net.last_linear.out_features))"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:53:26.592572Z","iopub.status.busy":"2022-07-26T08:53:26.592022Z","iopub.status.idle":"2022-07-26T08:55:34.587877Z","shell.execute_reply":"2022-07-26T08:55:34.586051Z","shell.execute_reply.started":"2022-07-26T08:53:26.592538Z"},"id":"7BYCTgZpBoOF","outputId":"f5d62b7b-5161-4e8c-e9e0-16d9d2fd2733","trusted":true},"outputs":[],"source":["# load Facenet\n","net = InceptionResnetV1(pretrained='vggface2', num_classes = 2, classify=True)\n","\n","# freeze all layers\n","for param in net.parameters():\n","  param.requires_grad = False\n","\n","# unfreeze last layer\n","in_ftrs = net.logits.in_features # number of input features of the last layer of the classifier\n","net.logits = nn.Linear(in_ftrs, 2)\n","\n","# change parameters data type and put them on gpu\n","net = net.double()\n","net = net.cuda()\n","\n","# create folder for storing results\n","result_folder = './results/'\n","if not os.path.exists(result_folder):\n","    os.makedirs(result_folder)\n","\n","# name for output files\n","logname = result_folder + net.__class__.__name__ + '_vgg_face2_to_kdef' + '__lr_' + str(base_learning_rate) + '__bs_' + str(batch_size) + '_full-retrain.csv'\n","\n","# Optimizer and criterion\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=5e-4)\n","\n","outModelName = 'pretrain'\n","if not os.path.exists(logname):\n","    with open(logname, 'w') as logfile:\n","        logwriter = csv.writer(logfile, delimiter=',')\n","        logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n","\n","# train the model\n","for epoch in range(start_epoch, max_epochs):\n","    adjust_learning_rate(optimizer, epoch)\n","    #print('finished adjust lr')\n","    train_loss, train_acc = train(net, epoch, trainloader, use_cuda=use_cuda)\n","    #print('finished train epoch ', epoch)\n","    test_loss, test_acc = test(net, epoch, testloader, outModelName, use_cuda=use_cuda)\n","    #print('finished test epoch ', epoch)\n","    with open(logname, 'a') as logfile:\n","        logwriter = csv.writer(logfile, delimiter=',')\n","        logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n","    print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:58:53.968294Z","iopub.status.busy":"2022-07-26T08:58:53.967889Z","iopub.status.idle":"2022-07-26T08:58:53.978443Z","shell.execute_reply":"2022-07-26T08:58:53.977302Z","shell.execute_reply.started":"2022-07-26T08:58:53.968267Z"},"id":"B1jgyVjH_cSx","trusted":true},"outputs":[],"source":["# read the results of training runs from the datafile\n","results = pd.read_csv(logname, sep =',')\n","results.head()\n","\n","train_accuracy = results['train acc'].values\n","test_accuracy = results['test acc'].values"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:58:57.906064Z","iopub.status.busy":"2022-07-26T08:58:57.905714Z","iopub.status.idle":"2022-07-26T08:58:58.134458Z","shell.execute_reply":"2022-07-26T08:58:58.133541Z","shell.execute_reply.started":"2022-07-26T08:58:57.906035Z"},"id":"4jxsjtnZDaE6","outputId":"f2a55f14-582c-4510-b6b6-840e13495712","trusted":true},"outputs":[],"source":["# plot curve of train and test accuracy\n","figureName = logname[:-4] + \".png\"\n","\n","plt.plot(results['epoch'].values, train_accuracy, label='train')\n","plt.plot(results['epoch'].values, test_accuracy, label='test')\n","plt.xlabel('Number of epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Train/Test Accuracy curve for {max_epochs} epochs')\n","plt.savefig(figureName)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:36:56.051877Z","iopub.status.busy":"2022-07-26T08:36:56.051396Z","iopub.status.idle":"2022-07-26T08:36:56.061177Z","shell.execute_reply":"2022-07-26T08:36:56.060219Z","shell.execute_reply.started":"2022-07-26T08:36:56.051840Z"},"id":"NeGJp7S8EY9R","outputId":"c0c33227-9b0a-4e0e-964e-e45f3caa9cc1","trusted":true},"outputs":[],"source":["# define function to test network on holdout data\n","def holdout_check(net, holdoutloader, use_cuda=use_cuda):\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in holdoutloader:\n","            inputes, targets = data[0], data[1]\n","            if use_cuda:\n","                inputes, targets = inputes.cuda(), targets.cuda()\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","    print('correct: {:d}  total: {:d}'.format(correct, total))\n","    print('accuracy = {:f}'.format(correct / total))"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T08:59:52.688196Z","iopub.status.busy":"2022-07-26T08:59:52.687837Z","iopub.status.idle":"2022-07-26T08:59:54.309764Z","shell.execute_reply":"2022-07-26T08:59:54.308779Z","shell.execute_reply.started":"2022-07-26T08:59:52.688167Z"},"id":"M3ZvjxjqJYSo","trusted":true},"outputs":[],"source":["# run test of network on holdout data\n","holdout_check(net, holdoutloader, use_cuda=use_cuda)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<p> Workaround to simply download the stored paramters of the trained model from kaggle: </p>\n","\n","<a href=\"./checkpoint/pretrain.t7\"> Download File </a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
